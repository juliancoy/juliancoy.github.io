<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Accessible Pitch Tuner (A4 = 440 Hz)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; }
    body { margin: 0; padding: 1.25rem; line-height: 1.5; }
    .wrap { max-width: 720px; margin: 0 auto; }
    h1 { margin: 0 0 .25rem; }
    .muted { color: #555; }
    .panel {
      margin-top: 1rem; padding: 1rem; border-radius: 14px;
      box-shadow: 0 6px 24px rgba(0,0,0,.08), 0 2px 8px rgba(0,0,0,.06);
    }
    .stat { font-size: 1.125rem; margin: .25rem 0; }
    .note {
      font-size: clamp(2rem, 6vw, 3rem);
      font-weight: 700;
      letter-spacing: .02em;
    }
    button {
      appearance: none; border: none; border-radius: 999px; padding: .8rem 1.1rem;
      font-size: 1rem; font-weight: 600; cursor: pointer; margin-right: .5rem;
      box-shadow: 0 4px 14px rgba(0,0,0,.1);
    }
    .primary { background: black; color: white; }
    .secondary { background: #eee; }
    .row { display: flex; gap: .5rem; align-items: center; flex-wrap: wrap; margin: .75rem 0; }
    label { display: inline-flex; gap: .5rem; align-items: center; }
    input[type="checkbox"] { transform: scale(1.2); }
    .live {
      position: absolute; left: -9999px; width: 1px; height: 1px; overflow: hidden;
    }
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Accessible Pitch Tuner</h1>
    <div class="muted">A4 reference = 440 Hz. Press <strong>Space</strong> to start/stop.</div>

    <div class="row" role="group" aria-label="Controls">
      <button id="toggle" class="primary" aria-pressed="false">Start Tuner</button>
      <label class="secondary" style="padding:.5rem 0 .5rem .75rem;border-radius:999px;">
        <input type="checkbox" id="speakToggle" checked aria-checked="true" />
        Announce notes
      </label>
    </div>

    <div class="panel" aria-live="polite" aria-atomic="true">
      <div id="noteText" class="note">—</div>
      <div class="stat"><strong>Frequency:</strong> <span id="freq">—</span> Hz</div>
      <div class="stat"><strong>Deviation:</strong> <span id="cents">—</span> cents (positive = sharp, negative = flat)</div>
      <div class="stat"><strong>Loudness:</strong> <span id="rms">—</span></div>
      <div class="stat" id="vadStatus">
        <strong>Activity:</strong> <span id="vadIndicator" style="display: inline-block; width: 12px; height: 12px; border-radius: 50%; background: #ccc; margin-left: 8px;"></span>
        <span id="vadText" style="margin-left: 8px;">Waiting for audio</span>
      </div>
    </div>

    <!-- Spectrogram display -->
    <div class="panel">
      <h3>Spectrogram</h3>
      <canvas id="spectrogramCanvas" width="600" height="200" style="width: 100%; height: 200px; border-radius: 8px;"></canvas>
    </div>

    <!-- Screen-reader only live announcements -->
    <div id="sr-live" class="live" aria-live="assertive" aria-atomic="true"></div>

    <details class="panel">
      <summary><strong>Keyboard</strong></summary>
      <ul>
        <li><kbd>Space</kbd>: Start/Stop tuner</li>
        <li><kbd>V</kbd>: Toggle voice announcements</li>
      </ul>
    </details>
  </div>

  <script>
    // ======= Configuration =======
    const A4 = 440;                 // reference
    const NOTE_NAMES = ['C','C sharp','D','D sharp','E','F','F sharp','G','G sharp','A','A sharp','B'];
    const MIN_CONFIDENCE_RMS = 0.005; // more sensitive minimal loudness to trust (RMS)
    const ACTIVITY_THRESHOLD = 0.008; // more sensitive RMS threshold for activity detection
    const ACTIVITY_FADE_THRESHOLD = 0.003; // more sensitive RMS threshold for activity fade
    const ACTIVITY_DEBOUNCE_MS = 500; // debounce time for activity state changes
    const HZ_MIN = 50;              // ignore sub-bass noise
    const HZ_MAX = 2000;            // cap for typical vocal/instrument range
    const ANALYSIS_BUFFER_SIZE = 4096; // larger buffer for better accuracy
    const SPEAK_COOLDOWN_MS = 3000; // longer delay between announcements

    // ======= State =======
    let audioCtx, analyser, micSource, scriptNode;
    let running = false;
    let speechOn = true;
    let lastSpokenNote = '';
    let lastSpokenAt = 0;
    let speakCooldownMs = SPEAK_COOLDOWN_MS; // longer delay between announcements
    let isSpeaking = false; // prevent simultaneous recording and speaking
    let micPermissionGranted = false;
    let lastTuningStatus = '';
    
    // Activity detection state
    let isActive = false;
    let lastActivityChange = 0;
    let activityStartTime = 0;
    let activityEndTime = 0;
    let analysisReady = false;
    
    // Spectrogram analysis
    let spectrogramFrames = [];
    let maxSpectrogramFrames = 100; // Store last 100 frames for analysis

    // ======= DOM =======
    const $toggle       = document.getElementById('toggle');
    const $speakToggle  = document.getElementById('speakToggle');
    const $note         = document.getElementById('noteText');
    const $freq         = document.getElementById('freq');
    const $cents        = document.getElementById('cents');
    const $rms          = document.getElementById('rms');
    const $srLive       = document.getElementById('sr-live');
    const $spectrogramCanvas = document.getElementById('spectrogramCanvas');
    const $vadIndicator = document.getElementById('vadIndicator');
    const $vadText      = document.getElementById('vadText');
    
    // WebGL spectrogram setup
    let gl, spectrogramTexture, spectrogramShader;
    let spectrogramWidth = 600;
    let spectrogramHeight = 200;
    let spectrogramData = new Float32Array(spectrogramWidth * spectrogramHeight * 4); // RGBA

    // ======= Helpers =======
    function freqToNoteData(f) {
      // Convert frequency to nearest MIDI note & cents deviation (A4=440)
      const n = Math.round(12 * Math.log2(f / A4)) + 69; // MIDI
      const noteIndex = (n % 12 + 12) % 12;
      const octave = Math.floor(n / 12) - 1;
      const noteName = NOTE_NAMES[noteIndex];
      const refHz = A4 * Math.pow(2, (n - 69) / 12);
      const cents = 1200 * Math.log2(f / refHz);
      return { noteName, octave, cents, midi: n, refHz };
    }

    function announce(text) {
      if (!speechOn) return;
      if (isSpeaking) return; // don't speak while already speaking
      const now = performance.now();
      if (now - lastSpokenAt < speakCooldownMs) return;
      if (!('speechSynthesis' in window)) return;

      isSpeaking = true;
      const utter = new SpeechSynthesisUtterance(text);
      utter.rate = 1.05;
      utter.pitch = 1.0;
      utter.volume = 1.0;
      
      utter.onend = function() {
        isSpeaking = false;
        lastSpokenAt = performance.now();
      };
      
      utter.onerror = function() {
        isSpeaking = false;
        lastSpokenAt = performance.now();
      };
      
      window.speechSynthesis.cancel(); // interrupt if needed
      window.speechSynthesis.speak(utter);

      // Also send to screen-reader live region
      $srLive.textContent = text;
    }

    function readableNote({noteName, octave}) {
      // Convert "A#" -> "A sharp"; "C#" -> "C sharp"
      const name = noteName.includes('#') ? noteName.replace('#', ' sharp') : noteName;
      return `${name} ${octave}`;
    }

    // Get tuning status based on cents deviation
    function getTuningStatus(cents) {
      const absCents = Math.abs(cents);
      if (absCents < 5) {
        return 'is right on the money';
      } else if (cents > 0) {
        return 'is slightly sharp';
      } else {
        return 'is slightly flat';
      }
    }

    function stopEverything() {
      running = false;
      $toggle.textContent = 'Start Tuner';
      $toggle.setAttribute('aria-pressed', 'false');
      if (scriptNode) { scriptNode.disconnect(); scriptNode = null; }
      if (analyser) { analyser.disconnect(); analyser = null; }
      if (micSource) { micSource.disconnect(); micSource = null; }
      if (audioCtx) { /* keep ctx alive; user can restart */ }
      
      // Reset activity detection state
      isActive = false;
      analysisReady = false;
      $note.textContent = '—';
      $freq.textContent = '—';
      $cents.textContent = '—';
      $rms.textContent = '—';
    }

    // ======= VAD Visual Indicators =======
    function updateVADIndicators() {
      if (isActive) {
        // Active state - green indicator (recording in progress)
        $vadIndicator.style.background = '#4CAF50';
        $vadText.textContent = 'Recording audio';
      } else if (analysisReady) {
        // Analysis in progress state - blue indicator (processing)
        $vadIndicator.style.background = '#2196F3';
        $vadText.textContent = 'Analysis in progress';
      } else {
        // Waiting state - gray indicator
        $vadIndicator.style.background = '#ccc';
        $vadText.textContent = 'Waiting for audio';
      }
    }

    // ======= Activity Detection =======
    function updateActivityDetection(rms) {
      const now = performance.now();
      
      // Debounce activity changes
      if (now - lastActivityChange < ACTIVITY_DEBOUNCE_MS) {
        return;
      }
      
      if (!isActive && rms >= ACTIVITY_THRESHOLD) {
        // Activity started
        isActive = true;
        analysisReady = false;
        activityStartTime = now;
        lastActivityChange = now;
        console.log('Activity started');
      } else if (isActive && rms < ACTIVITY_FADE_THRESHOLD) {
        // Activity ended/faded
        isActive = false;
        analysisReady = true; // Ready to provide analysis after activity ends
        activityEndTime = now;
        lastActivityChange = now;
        console.log('Activity ended, analysis ready');
      }
      
      // Update visual indicators
      updateVADIndicators();
    }

    // ======= Improved Pitch Detection (YIN Algorithm) =======
    function yinPitchDetection(buf, sampleRate) {
      const SIZE = buf.length;
      
      // Compute RMS for silence detection
      let rms = 0;
      for (let i = 0; i < SIZE; i++) {
        rms += buf[i] * buf[i];
      }
      rms = Math.sqrt(rms / SIZE);
      
      if (rms < MIN_CONFIDENCE_RMS) return { hz: -1, rms };

      // Apply Hanning window to reduce spectral leakage
      const windowed = new Float32Array(SIZE);
      for (let i = 0; i < SIZE; i++) {
        windowed[i] = buf[i] * (0.5 - 0.5 * Math.cos(2 * Math.PI * i / (SIZE - 1)));
      }

      // YIN algorithm implementation
      const MAX_TAU = Math.floor(sampleRate / HZ_MIN);
      const MIN_TAU = Math.floor(sampleRate / HZ_MAX);
      
      // Difference function
      const diff = new Float32Array(MAX_TAU);
      for (let tau = 0; tau < MAX_TAU; tau++) {
        let sum = 0;
        for (let j = 0; j < SIZE - tau; j++) {
          const delta = windowed[j] - windowed[j + tau];
          sum += delta * delta;
        }
        diff[tau] = sum;
      }

      // Cumulative mean normalized difference function
      const cmndf = new Float32Array(MAX_TAU);
      cmndf[0] = 1;
      let runningSum = 0;
      
      for (let tau = 1; tau < MAX_TAU; tau++) {
        runningSum += diff[tau];
        cmndf[tau] = diff[tau] * tau / runningSum;
      }

      // Find first local minimum below threshold
      const THRESHOLD = 0.1;
      let tau = MIN_TAU;
      while (tau < MAX_TAU - 1) {
        if (cmndf[tau] < THRESHOLD) {
          // Found candidate, refine with parabolic interpolation
          while (tau + 1 < MAX_TAU - 1 && cmndf[tau + 1] < cmndf[tau]) {
            tau++;
          }
          
          // Parabolic interpolation for better accuracy
          const x0 = tau - 1;
          const x1 = tau;
          const x2 = tau + 1;
          const y0 = cmndf[x0];
          const y1 = cmndf[x1];
          const y2 = cmndf[x2];
          
          if (y0 === undefined || y2 === undefined) break;
          
          const denom = 2 * (y0 - 2 * y1 + y2);
          if (Math.abs(denom) < 1e-10) break;
          
          const peak = x1 + (y0 - y2) / denom;
          const freq = sampleRate / peak;
          
          // Validate frequency range
          if (freq >= HZ_MIN && freq <= HZ_MAX) {
            return { hz: freq, rms };
          }
          break;
        }
        tau++;
      }

      return { hz: -1, rms };
    }

    // ======= Fallback to FFT-based detection =======
    function fftPitchDetection(buf, sampleRate) {
      const SIZE = buf.length;
      
      // Compute RMS
      let rms = 0;
      for (let i = 0; i < SIZE; i++) {
        rms += buf[i] * buf[i];
      }
      rms = Math.sqrt(rms / SIZE);
      
      if (rms < MIN_CONFIDENCE_RMS) return { hz: -1, rms };

      // Apply window function
      const windowed = new Float32Array(SIZE);
      for (let i = 0; i < SIZE; i++) {
        windowed[i] = buf[i] * (0.54 - 0.46 * Math.cos(2 * Math.PI * i / (SIZE - 1))); // Hamming
      }

      // Simple FFT magnitude calculation
      const magnitudes = new Float32Array(SIZE / 2);
      for (let k = 0; k < SIZE / 2; k++) {
        let real = 0;
        let imag = 0;
        for (let n = 0; n < SIZE; n++) {
          const angle = 2 * Math.PI * k * n / SIZE;
          real += windowed[n] * Math.cos(angle);
          imag -= windowed[n] * Math.sin(angle);
        }
        magnitudes[k] = Math.sqrt(real * real + imag * imag);
      }

      // Find peak in frequency range
      const minBin = Math.floor(HZ_MIN * SIZE / sampleRate);
      const maxBin = Math.floor(HZ_MAX * SIZE / sampleRate);
      
      let maxMagnitude = 0;
      let peakBin = -1;
      
      for (let k = minBin; k <= maxBin; k++) {
        if (magnitudes[k] > maxMagnitude) {
          maxMagnitude = magnitudes[k];
          peakBin = k;
        }
      }

      if (peakBin === -1 || maxMagnitude < 0.01) return { hz: -1, rms };

      // Convert bin to frequency
      const freq = peakBin * sampleRate / SIZE;
      return { hz: freq, rms };
    }

    // ======= WebGL Spectrogram =======
    function initSpectrogram() {
      gl = $spectrogramCanvas.getContext('webgl');
      if (!gl) {
        console.warn('WebGL not supported, falling back to 2D canvas');
        return false;
      }
      
      // Create texture for spectrogram data
      spectrogramTexture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, spectrogramTexture);
      gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, spectrogramWidth, spectrogramHeight, 0, gl.RGBA, gl.FLOAT, spectrogramData);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      
      // Simple shader for displaying texture
      const vertexShaderSource = `
        attribute vec2 a_position;
        varying vec2 v_texCoord;
        void main() {
          gl_Position = vec4(a_position, 0.0, 1.0);
          v_texCoord = a_position * 0.5 + 0.5;
        }
      `;
      
      const fragmentShaderSource = `
        precision mediump float;
        varying vec2 v_texCoord;
        uniform sampler2D u_texture;
        void main() {
          vec4 color = texture2D(u_texture, v_texCoord);
          // Apply color mapping (blue to red heatmap)
          float intensity = color.r;
          vec3 heatColor = vec3(
            intensity * 2.0,
            intensity * 1.5 - 0.5,
            1.0 - intensity * 2.0
          );
          gl_FragColor = vec4(heatColor, 1.0);
        }
      `;
      
      // Compile shaders
      const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
      const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
      spectrogramShader = createProgram(gl, vertexShader, fragmentShader);
      
      // Setup buffers
      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      const positions = [
        -1, -1,
         1, -1,
        -1,  1,
         1,  1,
      ];
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);
      
      const positionAttributeLocation = gl.getAttribLocation(spectrogramShader, "a_position");
      gl.enableVertexAttribArray(positionAttributeLocation);
      gl.vertexAttribPointer(positionAttributeLocation, 2, gl.FLOAT, false, 0, 0);
      
      return true;
    }
    
    function createShader(gl, type, source) {
      const shader = gl.createShader(type);
      gl.shaderSource(shader, source);
      gl.compileShader(shader);
      if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        console.error('Shader compile error:', gl.getShaderInfoLog(shader));
        gl.deleteShader(shader);
        return null;
      }
      return shader;
    }
    
    function createProgram(gl, vertexShader, fragmentShader) {
      const program = gl.createProgram();
      gl.attachShader(program, vertexShader);
      gl.attachShader(program, fragmentShader);
      gl.linkProgram(program);
      if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error('Program link error:', gl.getProgramInfoLog(program));
        return null;
      }
      return program;
    }
    
    function updateSpectrogram(magnitudes) {
      if (!gl) {
        console.log('WebGL context not available');
        return;
      }
      
      // Debug: Check if we have valid magnitudes
      if (magnitudes.length === 0) {
        console.log('No magnitude data');
        return;
      }
      
      // Shift existing data left (rolling buffer)
      for (let y = 0; y < spectrogramHeight; y++) {
        for (let x = 0; x < spectrogramWidth - 1; x++) {
          const srcIndex = (y * spectrogramWidth + (x + 1)) * 4;
          const dstIndex = (y * spectrogramWidth + x) * 4;
          spectrogramData[dstIndex] = spectrogramData[srcIndex];
          spectrogramData[dstIndex + 1] = spectrogramData[srcIndex + 1];
          spectrogramData[dstIndex + 2] = spectrogramData[srcIndex + 2];
          spectrogramData[dstIndex + 3] = spectrogramData[srcIndex + 3];
        }
      }
      
      // Add new data to the rightmost column
      // Find maximum magnitude for normalization
      let maxMagnitude = 0;
      for (let i = 0; i < magnitudes.length; i++) {
        if (magnitudes[i] > maxMagnitude) {
          maxMagnitude = magnitudes[i];
        }
      }
      
      console.log('Max magnitude:', maxMagnitude, 'Magnitudes length:', magnitudes.length);
      
      // Use a dynamic range that adapts to the signal
      const normalizationFactor = maxMagnitude > 0 ? maxMagnitude : 1;
      
      for (let y = 0; y < spectrogramHeight; y++) {
        // Map frequency bins to display height (linear scaling for now)
        const freqIndex = Math.floor((y / spectrogramHeight) * magnitudes.length);
        
        if (freqIndex >= 0 && freqIndex < magnitudes.length) {
          // Apply scaling to intensity
          let intensity = magnitudes[freqIndex] / normalizationFactor;
          intensity = Math.max(0, Math.min(1, intensity)); // Clamp to 0-1 range
          
          const pixelIndex = (y * spectrogramWidth + (spectrogramWidth - 1)) * 4;
          spectrogramData[pixelIndex] = intensity;
          spectrogramData[pixelIndex + 1] = intensity;
          spectrogramData[pixelIndex + 2] = intensity;
          spectrogramData[pixelIndex + 3] = 1.0;
        } else {
          // Fill with zeros if out of range
          const pixelIndex = (y * spectrogramWidth + (spectrogramWidth - 1)) * 4;
          spectrogramData[pixelIndex] = 0;
          spectrogramData[pixelIndex + 1] = 0;
          spectrogramData[pixelIndex + 2] = 0;
          spectrogramData[pixelIndex + 3] = 1.0;
        }
      }
      
      // Update texture
      gl.bindTexture(gl.TEXTURE_2D, spectrogramTexture);
      gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, spectrogramWidth, spectrogramHeight, gl.RGBA, gl.FLOAT, spectrogramData);
      
      // Set up shader and render
      gl.useProgram(spectrogramShader);
      
      // Set texture uniform
      const textureLocation = gl.getUniformLocation(spectrogramShader, "u_texture");
      gl.uniform1i(textureLocation, 0);
      
      // Clear and render
      gl.clearColor(0, 0, 0, 1);
      gl.clear(gl.COLOR_BUFFER_BIT);
      gl.viewport(0, 0, spectrogramWidth, spectrogramHeight);
      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }
    
    function computeSpectrum(buf) {
      const SIZE = buf.length;
      const windowed = new Float32Array(SIZE);
      
      // Apply Hamming window
      for (let i = 0; i < SIZE; i++) {
        windowed[i] = buf[i] * (0.54 - 0.46 * Math.cos(2 * Math.PI * i / (SIZE - 1)));
      }
      
      // Compute FFT magnitudes
      const magnitudes = new Float32Array(SIZE / 2);
      for (let k = 0; k < SIZE / 2; k++) {
        let real = 0;
        let imag = 0;
        for (let n = 0; n < SIZE; n++) {
          const angle = 2 * Math.PI * k * n / SIZE;
          real += windowed[n] * Math.cos(angle);
          imag -= windowed[n] * Math.sin(angle);
        }
        magnitudes[k] = Math.sqrt(real * real + imag * imag);
      }
      
      return magnitudes;
    }

    // ======= Main pitch detection function =======
    function detectPitch(buf, sampleRate) {
      // Try YIN algorithm first (more accurate for musical pitches)
      let result = yinPitchDetection(buf, sampleRate);
      
      // Fall back to FFT if YIN fails
      if (result.hz <= 0) {
        result = fftPitchDetection(buf, sampleRate);
      }
      
      return result;
    }

    // ======= Main loop =======
    async function start() {
      if (running) { stopEverything(); return; }
      try {
        if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
        micSource = audioCtx.createMediaStreamSource(stream);
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = ANALYSIS_BUFFER_SIZE;
        micSource.connect(analyser);

        // Initialize spectrogram
        initSpectrogram();

        const buf = new Float32Array(analyser.fftSize);
        running = true;
        $toggle.textContent = 'Stop Tuner';
        $toggle.setAttribute('aria-pressed', 'true');

        let lastNote = '';
        let lastStablePitch = null;
        let lastStableRMS = 0;
        
        function tick() {
          if (!running) return;
          analyser.getFloatTimeDomainData(buf);
          const { hz, rms } = detectPitch(buf, audioCtx.sampleRate);
          
          // Update activity detection
          updateActivityDetection(rms);
          
          // Update spectrogram visualization
          const magnitudes = computeSpectrum(buf);
          updateSpectrogram(magnitudes);
          
          // Only show analysis when activity has ended and we have a valid pitch
          if (analysisReady && hz > 0) {
            const d = freqToNoteData(hz);
            const rn = readableNote(d);
            const cents = d.cents;
            const tuningStatus = getTuningStatus(cents);

            $note.textContent = `${d.noteName}${d.octave}`;
            $freq.textContent = hz.toFixed(2);
            $cents.textContent = `${cents >= 0 ? '+' : ''}${cents.toFixed(1)}`;
            $rms.textContent = rms.toFixed(3);

            // Announce the analysis after activity ends
            if (rn !== lastNote || tuningStatus !== lastTuningStatus) {
              const fullAnnouncement = `${rn} ${tuningStatus}`;
              announce(fullAnnouncement);
              lastSpokenNote = rn;
              lastNote = rn;
              lastTuningStatus = tuningStatus;
              
              // Reset analysis ready state after announcing
              analysisReady = false;
            }
          } else if (!isActive && !analysisReady) {
            // No activity and no analysis ready - show waiting state
            $note.textContent = '—';
            $freq.textContent = '—';
            $cents.textContent = '—';
            $rms.textContent = rms.toFixed(3);
          } else if (isActive) {
            // Activity in progress - show real-time data but don't announce
            if (hz > 0) {
              const d = freqToNoteData(hz);
              $note.textContent = `${d.noteName}${d.octave}`;
              $freq.textContent = hz.toFixed(2);
              $cents.textContent = `${d.cents >= 0 ? '+' : ''}${d.cents.toFixed(1)}`;
              $rms.textContent = rms.toFixed(3);
            } else {
              $note.textContent = '—';
              $freq.textContent = '—';
              $cents.textContent = '—';
              $rms.textContent = rms.toFixed(3);
            }
          }
          requestAnimationFrame(tick);
        }
        tick();
      } catch (err) {
        console.error(err);
        alert('Microphone access failed or AudioContext error. Please allow mic access and try again.');
        stopEverything();
      }
    }

    // ======= UI wiring =======
    $toggle.addEventListener('click', start);
    $speakToggle.addEventListener('change', (e) => {
      speechOn = e.target.checked;
      $speakToggle.setAttribute('aria-checked', String(speechOn));
      if (!speechOn && 'speechSynthesis' in window) window.speechSynthesis.cancel();
    });

    // Keyboard shortcuts
    window.addEventListener('keydown', (e) => {
      if (e.code === 'Space') { e.preventDefault(); start(); }
      if (e.key.toLowerCase() === 'v') { $speakToggle.click(); }
    });

    // Politely resume AudioContext on user gesture (iOS)
    document.addEventListener('touchend', () => {
      if (audioCtx && audioCtx.state === 'suspended') audioCtx.resume();
    }, { passive: true });
  </script>
</body>
</html>
